{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7123f3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def greet(name, intensity):\n",
    "    return \"Hello, \" + name + \"!\" * int(intensity)\n",
    "\n",
    "demo = gr.Interface(\n",
    "    fn=greet,\n",
    "    inputs=[\"text\", \"slider\"],\n",
    "    outputs=[\"text\"],\n",
    ")\n",
    "\n",
    "demo.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456f7940",
   "metadata": {},
   "outputs": [],
   "source": [
    "gr.themes.builder()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2cae5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "from gradio.themes.base import Base\n",
    "import time\n",
    "\n",
    "class Seafoam(Base):\n",
    "    pass\n",
    "\n",
    "seafoam = Seafoam()\n",
    "\n",
    "with gr.Blocks(theme=seafoam) as demo:\n",
    "    textbox = gr.Textbox(label=\"Name\")\n",
    "    slider = gr.Slider(label=\"Count\", minimum=0, maximum=100, step=1)\n",
    "    with gr.Row():\n",
    "        button = gr.Button(\"Submit\", variant=\"primary\")\n",
    "        clear = gr.Button(\"Clear\")\n",
    "    output = gr.Textbox(label=\"Output\")\n",
    "\n",
    "    def repeat(name, count):\n",
    "        time.sleep(3)\n",
    "        return name * count\n",
    "    \n",
    "    button.click(repeat, [textbox, slider], output)\n",
    "\n",
    "demo.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19cff3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "with gr.Blocks(theme=gr.themes.Soft()) as demo:\n",
    "     def greet(name, intensity):\n",
    "    return \"Hello, \" + name + \"!\" * int(intensity)\n",
    "\n",
    "\n",
    "demo = gr.Interface(\n",
    "    fn=greet,\n",
    "    inputs=[\"text\", \"slider\"],\n",
    "    outputs=[\"text\"],\n",
    ")\n",
    "\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6865f1ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "title = \"Multiple Interfaces\"\n",
    "\n",
    "#app 1\n",
    "def user_greeting(name):\n",
    "    return \"Hi! \" + name + \" Welcome to your first Gradio application!ðŸ˜Ž\"\n",
    "\n",
    "#app 2\n",
    "def user_help(do):\n",
    "    return \"So today we will do \" + do + \"using Gradio. Great choice!\"\n",
    "\n",
    "#interface 1\n",
    "app1 =  gr.Interface(fn = user_greeting, inputs=\"text\", outputs=\"text\")\n",
    "#interface 2\n",
    "\n",
    "app2 =  gr.Interface(fn = user_help, inputs=\"text\", outputs=\"text\")\n",
    "\n",
    "demo = gr.TabbedInterface([app1, app2], [\"Welcome\", \"What to do\"])\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5724fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f95049",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverse_audio(audio):\n",
    "    sr, data = audio\n",
    "    return (sr, np.flipud(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3061c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_audio = gr.Audio(sources=[\"microphone\"])\n",
    "demo = gr.Interface(\n",
    "    fn=reverse_audio,\n",
    "    inputs=input_audio,\n",
    "    outputs=\"audio\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6114a395",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    demo.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb12549e",
   "metadata": {},
   "source": [
    "Speech to Audio with Gradio ASR and transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8fad13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "from transformers import pipeline\n",
    "import numpy as np\n",
    "\n",
    "# Initialize the ASR pipeline\n",
    "transcriber = pipeline(\"automatic-speech-recognition\", model=\"openai/whisper-base.en\")\n",
    "\n",
    "def transcribe(audio):\n",
    "    sr, y = audio # Extract sampling rate and audio data\n",
    "    y = y.astype(np.float32) # Convert audio data to float32\n",
    "    y /= np.max(np.abs(y)) # Normalize the audio data\n",
    "    return transcriber({\"sampling_rate\": sr, \"raw\": y})[\"text\"] # Transcribe the audio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9608ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo = gr.Interface(\n",
    "    transcribe,\n",
    "    gr.Audio(sources=[\"microphone\"]),\n",
    "    \"text\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a78cbf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "demo.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e99dcf",
   "metadata": {},
   "source": [
    "Gradio Interface with ASR returning text to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2d08f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "from transformers import pipeline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize the ASR pipeline\n",
    "transcriber = pipeline(\"automatic-speech-recognition\", model=\"openai/whisper-base.en\")\n",
    "\n",
    "def transcribe(audio):\n",
    "    sr, y = audio\n",
    "    y = y.astype(np.float32)\n",
    "    y /= np.max(np.abs(y))\n",
    "    return transcriber({\"sampling_rate\": sr, \"raw\": y})[\"text\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7901810c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dataframe from transcription\n",
    "\n",
    "def transcribe_to_df(audio):\n",
    "    transcribed_text = transcribe(audio)\n",
    "    # Create a DataFrame with the transcribed text\n",
    "    df = pd.DataFrame({\"Transcription\": [transcribed_text]})\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16903d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo = gr.Interface(\n",
    "    transcribe_to_df,\n",
    "    gr.Audio(sources=[\"microphone\"]),\n",
    "    outputs=\"dataframe\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64657659",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "demo.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7724cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_push = pd.DataFrame(dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae8e20b",
   "metadata": {},
   "source": [
    "Gradio audio caputre to Assembly AI sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8cd098",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "# Placeholder function to stream audio to AssemblyAI\n",
    "def stream_audio_to_assemblyai(audio_stream):\n",
    "    # This function should establish a WebSocket connection to AssemblyAI,\n",
    "    # send the audio stream in real-time, and return the transcription and sentiment analysis results.\n",
    "    # The actual implementation depends on the AssemblyAI API and WebSocket handling.\n",
    "    pass\n",
    "\n",
    "# Gradio interface for live audio input\n",
    "def process_live_audio(audio_stream):\n",
    "    # Process the live audio stream\n",
    "    transcription_and_sentiment = stream_audio_to_assemblyai(audio_stream)\n",
    "    return transcription_and_sentiment\n",
    "\n",
    "iface = gr.Interface(\n",
    "    fn=process_live_audio,\n",
    "    inputs=gr.Audio(sources=[\"microphone\"], streaming=True),\n",
    "    outputs=[\"text\", \"json\"], # Assuming sentiment analysis results are returned in JSON format\n",
    "    live=True,\n",
    ")\n",
    "\n",
    "iface.launch()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495d8c05",
   "metadata": {},
   "source": [
    "Gradio ASR to Assembly AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd57f49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "from transformers import pipeline\n",
    "import numpy as np\n",
    "import requests\n",
    "\n",
    "# Initialize the ASR pipeline\n",
    "transcriber = pipeline(\"automatic-speech-recognition\", model=\"openai/whisper-base.en\")\n",
    "\n",
    "def transcribe(audio):\n",
    "    sr, y = audio\n",
    "    y = y.astype(np.float32)\n",
    "    y /= np.max(np.abs(y))\n",
    "    return transcriber({\"sampling_rate\": sr, \"raw\": y})[\"text\"]\n",
    "\n",
    "def send_to_assemblyai(text):\n",
    "    # Replace with your actual AssemblyAI API endpoint and API key\n",
    "    url = \"https://api.assemblyai.com/v2/transcript\"\n",
    "    headers = {\n",
    "        \"Authorization\": \"6898dad2ca8f4fd2862cfe04fd51e992\"\n",
    "    }\n",
    "    data = {\n",
    "        \"text\": text,\n",
    "        # Additional parameters as needed\n",
    "    }\n",
    "    response = requests.post(url, headers=headers, json=data)\n",
    "    return response.json()\n",
    "\n",
    "def process_audio(audio):\n",
    "    transcribed_text = transcribe(audio)\n",
    "    assemblyai_response = send_to_assemblyai(transcribed_text)\n",
    "    return assemblyai_response\n",
    "\n",
    "iface = gr.Interface(\n",
    "    fn=process_audio,\n",
    "    inputs=gr.Audio(sources=[\"microphone\"]),\n",
    "    outputs=\"json\",\n",
    ")\n",
    "\n",
    "iface.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae4146e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# `pip3 install assemblyai` (macOS)\n",
    "# `pip install assemblyai` (Windows)\n",
    "\n",
    "import assemblyai as aai\n",
    "\n",
    "aai.settings.api_key = \"6898dad2ca8f4fd2862cfe04fd51e992\"\n",
    "transcriber = aai.Transcriber()\n",
    "\n",
    "transcript = transcriber.transcribe(\"https://storage.googleapis.com/aai-web-samples/news.mp4\")\n",
    "# transcript = transcriber.transcribe(\"./my-local-audio-file.wav\")\n",
    "\n",
    "print(transcript.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e56c36b",
   "metadata": {},
   "source": [
    "# Gradio ASR to output txt file (Works!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f80a881d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\c_mar\\anaconda3\\envs\\dev\\lib\\site-packages\\transformers\\utils\\generic.py:260: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "Running on public URL: https://644900d8023a5d7cd1.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://644900d8023a5d7cd1.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:    Exception in ASGI application\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\c_mar\\anaconda3\\envs\\dev\\lib\\site-packages\\uvicorn\\protocols\\http\\h11_impl.py\", line 407, in run_asgi\n",
      "    result = await app(  # type: ignore[func-returns-value]\n",
      "  File \"C:\\Users\\c_mar\\anaconda3\\envs\\dev\\lib\\site-packages\\uvicorn\\middleware\\proxy_headers.py\", line 69, in __call__\n",
      "    return await self.app(scope, receive, send)\n",
      "  File \"C:\\Users\\c_mar\\anaconda3\\envs\\dev\\lib\\site-packages\\fastapi\\applications.py\", line 1054, in __call__\n",
      "    await super().__call__(scope, receive, send)\n",
      "  File \"C:\\Users\\c_mar\\anaconda3\\envs\\dev\\lib\\site-packages\\starlette\\applications.py\", line 123, in __call__\n",
      "    await self.middleware_stack(scope, receive, send)\n",
      "  File \"C:\\Users\\c_mar\\anaconda3\\envs\\dev\\lib\\site-packages\\starlette\\middleware\\errors.py\", line 186, in __call__\n",
      "    raise exc\n",
      "  File \"C:\\Users\\c_mar\\anaconda3\\envs\\dev\\lib\\site-packages\\starlette\\middleware\\errors.py\", line 164, in __call__\n",
      "    await self.app(scope, receive, _send)\n",
      "  File \"C:\\Users\\c_mar\\anaconda3\\envs\\dev\\lib\\site-packages\\gradio\\route_utils.py\", line 680, in __call__\n",
      "    await self.app(scope, receive, send)\n",
      "  File \"C:\\Users\\c_mar\\anaconda3\\envs\\dev\\lib\\site-packages\\starlette\\middleware\\exceptions.py\", line 62, in __call__\n",
      "    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)\n",
      "  File \"C:\\Users\\c_mar\\anaconda3\\envs\\dev\\lib\\site-packages\\starlette\\_exception_handler.py\", line 64, in wrapped_app\n",
      "    raise exc\n",
      "  File \"C:\\Users\\c_mar\\anaconda3\\envs\\dev\\lib\\site-packages\\starlette\\_exception_handler.py\", line 53, in wrapped_app\n",
      "    await app(scope, receive, sender)\n",
      "  File \"C:\\Users\\c_mar\\anaconda3\\envs\\dev\\lib\\site-packages\\starlette\\routing.py\", line 758, in __call__\n",
      "    await self.middleware_stack(scope, receive, send)\n",
      "  File \"C:\\Users\\c_mar\\anaconda3\\envs\\dev\\lib\\site-packages\\starlette\\routing.py\", line 778, in app\n",
      "    await route.handle(scope, receive, send)\n",
      "  File \"C:\\Users\\c_mar\\anaconda3\\envs\\dev\\lib\\site-packages\\starlette\\routing.py\", line 299, in handle\n",
      "    await self.app(scope, receive, send)\n",
      "  File \"C:\\Users\\c_mar\\anaconda3\\envs\\dev\\lib\\site-packages\\starlette\\routing.py\", line 79, in app\n",
      "    await wrap_app_handling_exceptions(app, request)(scope, receive, send)\n",
      "  File \"C:\\Users\\c_mar\\anaconda3\\envs\\dev\\lib\\site-packages\\starlette\\_exception_handler.py\", line 64, in wrapped_app\n",
      "    raise exc\n",
      "  File \"C:\\Users\\c_mar\\anaconda3\\envs\\dev\\lib\\site-packages\\starlette\\_exception_handler.py\", line 53, in wrapped_app\n",
      "    await app(scope, receive, sender)\n",
      "  File \"C:\\Users\\c_mar\\anaconda3\\envs\\dev\\lib\\site-packages\\starlette\\routing.py\", line 77, in app\n",
      "    await response(scope, receive, send)\n",
      "  File \"C:\\Users\\c_mar\\anaconda3\\envs\\dev\\lib\\site-packages\\starlette\\responses.py\", line 351, in __call__\n",
      "    await send(\n",
      "  File \"C:\\Users\\c_mar\\anaconda3\\envs\\dev\\lib\\site-packages\\starlette\\_exception_handler.py\", line 50, in sender\n",
      "    await send(message)\n",
      "  File \"C:\\Users\\c_mar\\anaconda3\\envs\\dev\\lib\\site-packages\\starlette\\_exception_handler.py\", line 50, in sender\n",
      "    await send(message)\n",
      "  File \"C:\\Users\\c_mar\\anaconda3\\envs\\dev\\lib\\site-packages\\starlette\\middleware\\errors.py\", line 161, in _send\n",
      "    await send(message)\n",
      "  File \"C:\\Users\\c_mar\\anaconda3\\envs\\dev\\lib\\site-packages\\uvicorn\\protocols\\http\\h11_impl.py\", line 511, in send\n",
      "    output = self.conn.send(event=h11.EndOfMessage())\n",
      "  File \"C:\\Users\\c_mar\\anaconda3\\envs\\dev\\lib\\site-packages\\h11\\_connection.py\", line 512, in send\n",
      "    data_list = self.send_with_data_passthrough(event)\n",
      "  File \"C:\\Users\\c_mar\\anaconda3\\envs\\dev\\lib\\site-packages\\h11\\_connection.py\", line 545, in send_with_data_passthrough\n",
      "    writer(event, data_list.append)\n",
      "  File \"C:\\Users\\c_mar\\anaconda3\\envs\\dev\\lib\\site-packages\\h11\\_writers.py\", line 67, in __call__\n",
      "    self.send_eom(event.headers, write)\n",
      "  File \"C:\\Users\\c_mar\\anaconda3\\envs\\dev\\lib\\site-packages\\h11\\_writers.py\", line 96, in send_eom\n",
      "    raise LocalProtocolError(\"Too little data for declared Content-Length\")\n",
      "h11._util.LocalProtocolError: Too little data for declared Content-Length\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "from transformers import pipeline\n",
    "import numpy as np\n",
    "\n",
    "# Initialize the ASR pipeline\n",
    "transcriber = pipeline(\"automatic-speech-recognition\", model=\"openai/whisper-base.en\")\n",
    "\n",
    "def transcribe_and_save(audio):\n",
    "    sr, y = audio\n",
    "    y = y.astype(np.float32)\n",
    "    y /= np.max(np.abs(y))\n",
    "    transcription = transcriber({\"sampling_rate\": sr, \"raw\": y})[\"text\"]\n",
    "    \n",
    "    # Write the transcription to a file\n",
    "    with open(\"transcription.txt\", \"w\") as file:\n",
    "        file.write(transcription)\n",
    "    \n",
    "    return transcription\n",
    "\n",
    "# Create the Gradio interface\n",
    "demo = gr.Interface(\n",
    "    transcribe_and_save,\n",
    "    gr.Audio(sources=[\"microphone\"]),\n",
    "    \"text\",\n",
    ")\n",
    "\n",
    "demo.launch(share=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5bf3a825",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sentiment analysis with OpenAI\n",
    "#preprocess txt file\n",
    "\n",
    "with open('transcription.txt', 'r', encoding=\"utf-8\") as file:\n",
    "    text = file.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f90c1a55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt-4-turbo-2024-04-09\n",
      "whisper-1\n",
      "davinci-002\n",
      "gpt-4-turbo\n",
      "gpt-4-1106-preview\n",
      "gpt-4-0613\n",
      "dall-e-2\n",
      "tts-1-hd-1106\n",
      "tts-1-hd\n",
      "gpt-4\n",
      "gpt-4-1106-vision-preview\n",
      "gpt-3.5-turbo-0125\n",
      "gpt-3.5-turbo\n",
      "gpt-3.5-turbo-16k\n",
      "gpt-3.5-turbo-16k-0613\n",
      "tts-1\n",
      "dall-e-3\n",
      "gpt-3.5-turbo-0613\n",
      "gpt-3.5-turbo-0301\n",
      "gpt-3.5-turbo-instruct-0914\n",
      "babbage-002\n",
      "gpt-3.5-turbo-instruct\n",
      "tts-1-1106\n",
      "text-embedding-3-large\n",
      "gpt-4-0125-preview\n",
      "text-embedding-3-small\n",
      "text-embedding-ada-002\n",
      "gpt-3.5-turbo-1106\n",
      "gpt-4-turbo-preview\n",
      "gpt-4-vision-preview\n"
     ]
    }
   ],
   "source": [
    "model_lst = openai.Model.list()\n",
    "\n",
    "for i in model_lst['data']:\n",
    "    print(i['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5819097a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sentiment of the text is I am a girl and I am 14 years old. I am from Russia. I like to read books and watch movies. I am a student and I am in the 9th grade. I am looking for a pen pal from any country. I am looking forward to hearing from you. I am waiting for your letter. Bye.\n",
      "\n",
      "Sentiment analysis results:\n",
      "\n",
      "Sentiment \t\t\t\tCalculated value \n",
      "\n",
      "Positive \t\t\t\t0.0 \n",
      "Neutral \t\t\t\t0.0 \n",
      "Negative \t\t\t\t0.0 \n",
      "\n",
      "Sentiment value of the text: 0.0\n",
      "\n",
      "The following text is also analyzed:\n",
      "\n",
      "This is a test I feel\n"
     ]
    }
   ],
   "source": [
    "#analysis\n",
    "\n",
    "import openai\n",
    "import time\n",
    "\n",
    "# Set your OpenAI API key\n",
    "openai.api_key = \"sk-proj-mU2gUtjNmEIhJNoILJxNT3BlbkFJkiUSTSKHz7jJtwBuqGQ3\"\n",
    "\n",
    "# Function to perform sentiment analysis using OpenAI\n",
    "def perform_sentiment_analysis(text):\n",
    "    prompt = f\"Please analyze the sentiment of the following text:\\n{text}\"\n",
    "    response = openai.Completion.create(\n",
    "        engine=\"davinci-002\",\n",
    "        prompt=prompt,\n",
    "        temperature=0.1,\n",
    "        max_tokens=128,\n",
    "        n=1,\n",
    "        stop=None,\n",
    "        timeout=10,\n",
    "    )\n",
    "    sentiment = response.choices[0].text.strip().replace(\"The sentiment of the text is \", \"\").rstrip('.')\n",
    "    return sentiment\n",
    "\n",
    "# Read the text file\n",
    "with open('transcription.txt', 'r', encoding=\"utf-8\") as file:\n",
    "    text = file.read()\n",
    "\n",
    "# Perform sentiment analysis\n",
    "sentiment = perform_sentiment_analysis(text)\n",
    "print(f\"The sentiment of the text is {sentiment}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d14f7f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399a90e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
